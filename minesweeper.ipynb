{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Please install the following python libraries\n",
    "- python3: https://www.python.org/\n",
    "- numpy: https://numpy.org/install/\n",
    "- tqdm: https://github.com/tqdm/tqdm#installation\n",
    "- matplotlib: https://matplotlib.org/stable/users/installing/index.html\n",
    "\n",
    "If you encounter the error: \"IProgress not found. Please update jupyter & ipywidgets\"\n",
    "    \n",
    "Please install the ipywidgets as follows:\n",
    "\n",
    "    with pip, do\n",
    "    - pip install ipywidgets\n",
    "    \n",
    "    with conda, do\n",
    "    - conda install -c conda-forge ipywidgets\n",
    "    \n",
    "Restart your notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Deep Neural Networks using Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will use the Pytorch library (https://pytorch.org/) to build and train our deep neural networks. In the deep learning literature, especially in the research community, Pytorch is SUPER popular due to its automatic differentiation and dynamic computational graph (i.e., the graph is automatically generated, which is different from tensorflow where you have to define them beforehand). Briefly spearking, using Pytorch, you only have to build your neural network, define the forward pass, and the loss function. The library will automatically compute the weights and perform the backpropagation for you. For more details about Pytorch, we recommend you check the tutorails on the offical website to learn the basics (https://pytorch.org/tutorials/). \n",
    "\n",
    "Please try to learn the basics as much as you can. If you have any questions, feel free to ask them on Piazza or TA hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please install the Pytorch library on your computer before you run this notebook.\n",
    "\n",
    "The installation instructions can be found here. (https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import random\n",
    "import gym\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN with MineSweeper\n",
    "\n",
    "Here, let's write a DQN agent to resolve the Minesweeper problem in this question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\"\"\" Here is the implementation of the FourRooms\n",
    "    Note that, the reward function is changed to be:\n",
    "        - If the agent reaches the goal, it receives 0 and the episode terminates.\n",
    "        - For other time step, the agent receives -1 reward.\n",
    "\"\"\"\n",
    "class MineSweeper(object):\n",
    "    def __init__(self, width, height, mines, limit=None, use_random_mines=False, scale_mines=False):\n",
    "        #\n",
    "        self.mine_map = np.zeros((width, height))\n",
    "        self.state = np.full((width, height), -1, dtype=np.int16 )\n",
    "\n",
    "        # We define the observation space consisting of all empty cells\n",
    "        # Note: We have to flip the coordinates from (row_idx, column_idx) -> (x, y),\n",
    "        # where x = column_idx, y = 10 - row_idx\n",
    "        actions = list(range(width * height))\n",
    "        self.observation_space = actions\n",
    "        # We define the action space\n",
    "        self.action_space = actions\n",
    "        self.action_names = actions\n",
    "\n",
    "        self.action = None  # track the agent's action\n",
    "        self.t = 0  # track the current time step in one episode\n",
    "\n",
    "        self.run = 0\n",
    "        self.scale_mines = scale_mines\n",
    "\n",
    "        self.num_mines = mines #if not use_random_mines else random.randint(0, mines)\n",
    "        self.mines = mines\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.limit = width * height * 2 if limit == None else limit\n",
    "        self.revealed_squares = 0\n",
    "\n",
    "    def __action_space(self, width, height):\n",
    "        actions = []\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                actions.append((x, y))\n",
    "        return actions\n",
    "        \n",
    "\n",
    "    def __action_index_to_coord(self, index):\n",
    "        y = math.floor(index / self.width) \n",
    "        x = index - y * self.width\n",
    "\n",
    "        return (x, y)\n",
    "\n",
    "    \n",
    "    def available_actions(self):\n",
    "        vals = self.state.flatten()\n",
    "        acts = []\n",
    "        index = 0\n",
    "        for val in vals: \n",
    "            if val == -1:\n",
    "                acts.append(index)\n",
    "            index += 1\n",
    "\n",
    "        return acts\n",
    "\n",
    "    @staticmethod\n",
    "    def arr_coords_to_four_room_coords(arr_coords_list):\n",
    "        \"\"\"\n",
    "        Function converts the array coordinates to the Four Rooms coordinates (i.e, The origin locates at bottom left).\n",
    "        E.g., The coordinates (0, 0) in the numpy array is mapped to (0, 10) in the Four Rooms coordinates.\n",
    "        Args:\n",
    "            arr_coords_list (list): a list variable consists of tuples of locations in the numpy array\n",
    "\n",
    "        Return:\n",
    "            four_room_coords_list (list): a list variable consists of tuples of converted locations in the\n",
    "                                          Four Rooms environment.\n",
    "        \"\"\"\n",
    "        # Note: We have to flip the coordinates from (row_idx, column_idx) -> (x, y),\n",
    "        # where x = column_idx, y = 10 - row_idx\n",
    "        four_room_coords_list = [(column_idx, 10 - row_idx) for (row_idx, column_idx) in arr_coords_list]\n",
    "        return four_room_coords_list\n",
    "\n",
    "    def reset(self):\n",
    "        # We reset the agent's location to the start location\n",
    "        self.mine_map = np.zeros((self.width, self.height))\n",
    "        self.state = np.full((self.width, self.height), -1, dtype=np.int32)\n",
    "\n",
    "        # We reset the timeout tracker to be 0\n",
    "        self.t = 0\n",
    "\n",
    "        if self.scale_mines:\n",
    "            self.num_mines = math.floor(self.run) if self.run < self.mines else self.mines\n",
    "            self.run += .1\n",
    "        self.revealed_squares = 0\n",
    "\n",
    "        # We set the information\n",
    "        info = {}\n",
    "        \n",
    "        return self.state.flatten(), info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            action (string): a tuple (x, y) which represents where the agent clicks\n",
    "        \"\"\"\n",
    "\n",
    "        action = self.__action_index_to_coord(action)\n",
    "        if self.t == 0:\n",
    "            self.setup_mines(action)\n",
    "        \n",
    "        if self.t == self.limit:\n",
    "            return self.state.flatten(), -1, True, False, {}\n",
    "    \n",
    "        x, y = action\n",
    "        \n",
    "        # did we hit a mine\n",
    "        unknown_neighbors = all(self.state[neighbor_y, neighbor_x] == -1 for neighbor_x, neighbor_y in self.__get_neighbors(x, y))\n",
    "        # if unknown_neighbors and self.mine_map[y, x] == 1:\n",
    "        #    return self.state.flatten(), -1 * (self.width + self.height), True, False, {}\n",
    "        # if self.mine_map[y, x] == 1 and unknown_neighbors:\n",
    "        #     return self.state.flatten(), -1/2 * self.width * self.height, True, False, {} \n",
    "        if self.mine_map[y, x] == 1:\n",
    "            return self.state.flatten(), -1 * self.width * self.height, True, False, {}\n",
    "        \n",
    "        old_value = self.state[y, x]\n",
    "        tiles_revealed = self.reveal_square_tile(x, y)\n",
    "        self.revealed_squares += tiles_revealed\n",
    "        # is the game over\n",
    "        if all((self.mine_map[neigh_y, neigh_x] == 1 or self.state[neigh_y, neigh_x] != -1) for neigh_x,neigh_y in self.__action_space(self.width, self.height)):\n",
    "            return  self.state.flatten(), self.width * self.height, True, False, {}\n",
    "        \n",
    "        reward = 1\n",
    "        # did we reveal a tile with no known neighbors\n",
    "        if unknown_neighbors and self.t != 0:\n",
    "           reward = .25\n",
    "        # did we select a tile we have already pressed?\n",
    "        if old_value != -1:\n",
    "            reward = -1\n",
    "\n",
    "        self.t += 1\n",
    "        \n",
    "        return self.state.flatten(), reward, False, False, {}\n",
    "\n",
    "    def reveal_square_tile(self, x, y):\n",
    "        tiles_to_reveal = [(x, y)]\n",
    "        tiles_revealed = 0\n",
    "        seen = []\n",
    "        while len(tiles_to_reveal) != 0:\n",
    "            x, y = tiles_to_reveal.pop()\n",
    "            if self.state[y, x] != -1:\n",
    "                continue\n",
    "            mines_around = self.__count_surrounding_mines(x, y)\n",
    "            self.state[y, x] = mines_around\n",
    "            tiles_revealed += 1\n",
    "            if mines_around == 0:\n",
    "                neighbors = self.__get_neighbors(x, y)\n",
    "                for new_x, new_y in neighbors:\n",
    "                    if (new_x, new_y) in seen:\n",
    "                        continue\n",
    "                    else:\n",
    "                        tiles_to_reveal.append((new_x, new_y))\n",
    "        return tiles_revealed\n",
    "             \n",
    "    def __count_surrounding_mines(self, x, y):\n",
    "        neighbors = self.__get_neighbors(x, y)\n",
    "        \n",
    "        count = 0\n",
    "        for neighbor_x, neighbor_y in neighbors:\n",
    "            count += self.mine_map[neighbor_y, neighbor_x]\n",
    "\n",
    "        return count\n",
    "\n",
    "    def __get_neighbors(self, x, y):\n",
    "        neighbors = []\n",
    "        if x != 0:\n",
    "            if y != 0:\n",
    "                neighbors.append((x - 1, y - 1))\n",
    "            if y != self.height - 1: \n",
    "                neighbors.append((x - 1, y + 1))\n",
    "            neighbors.append((x - 1, y))\n",
    "        if x != self.width - 1:\n",
    "            if y != 0:\n",
    "                neighbors.append((x + 1, y - 1))\n",
    "            if y != self.height - 1: \n",
    "                neighbors.append((x + 1, y + 1))\n",
    "            neighbors.append((x + 1, y))\n",
    "        if y != 0:\n",
    "            neighbors.append((x, y - 1))\n",
    "        if y != self.height - 1:\n",
    "            neighbors.append((x, y + 1))\n",
    "\n",
    "        return neighbors\n",
    "\n",
    "    def setup_mines(self, first_action):\n",
    "        mine_locations = [first_action] + self.__get_neighbors(first_action[0], first_action[1])\n",
    "        for mine in range(self.num_mines):\n",
    "            mine = self.gen_random_mine(mine_locations)\n",
    "            mine_locations.append(mine)\n",
    "            self.mine_map[mine[1], mine[0]] = 1\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "    def gen_random_mine(self, curr_mines):\n",
    "        x = random.randint(0, self.width - 1)\n",
    "        y = random.randint(0, self.height - 1)\n",
    "        while (x, y) in curr_mines:\n",
    "            x,y  = self.gen_random_mine(curr_mines)\n",
    "        return (x, y)\n",
    "\n",
    "\n",
    "\n",
    "    # def render(self):\n",
    "    #     # plot the agent and the goal\n",
    "    #     # empty cell = 0\n",
    "    #     # wall cell = 1\n",
    "    #     # agent cell = 2\n",
    "    #     # goal cell = 3\n",
    "    #     plot_arr = self.grid.copy()\n",
    "    #     plot_arr[10 - self.agent_location[1], self.agent_location[0]] = 2\n",
    "    #     plot_arr[10 - self.goal_location[1], self.goal_location[0]] = 3\n",
    "    #     plt.clf()\n",
    "    #     plt.title(f\"state={self.agent_location}, act={self.action}\")\n",
    "    #     plt.imshow(plot_arr)\n",
    "    #     plt.show(block=False)\n",
    "    #     plt.pause(0.1)\n",
    "\n",
    "    # @staticmethod\n",
    "    # def test():\n",
    "    #     my_env = FourRooms()\n",
    "    #     state, _ = my_env.reset()\n",
    "\n",
    "    #     for _ in range(100):\n",
    "    #         action = np.random.choice(list(my_env.action_space.keys()), 1)[0]\n",
    "\n",
    "    #         next_state, reward, done, _, _ = my_env.step(action)\n",
    "    #         my_env.render()\n",
    "\n",
    "    #         if done:\n",
    "    #             state, _ = my_env.reset()\n",
    "    #         else:\n",
    "    #             state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Deep Q network\n",
    "\n",
    "Before, we write a DQN agent. Let's define a Deep Q network as we did in Q1. Otherwise, you could also adapt your\n",
    "implementation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized weight initialization\n",
    "def customized_weights_init(m):\n",
    "    # compute the gain\n",
    "    gain = nn.init.calculate_gain('relu')\n",
    "    # init the convolutional layer\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        # init the params using uniform\n",
    "        nn.init.xavier_uniform_(m.weight, gain=gain)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    # init the linear layer\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # init the params using uniform\n",
    "        nn.init.xavier_uniform_(m.weight, gain=gain)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNet(nn.Module):\n",
    "    def __init__(self, input_dim, num_hidden_layer, dim_hidden_layer, output_dim):\n",
    "        super(DeepQNet, self).__init__()\n",
    "\n",
    "        \"\"\"CODE HERE: construct your Deep neural network\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.input_layer = nn.Linear(input_dim, dim_hidden_layer)\n",
    "        self.activation_layer = [nn.ReLU() for n in range(num_hidden_layer)]\n",
    "        self.hidden_layers = [nn.Linear(dim_hidden_layer, dim_hidden_layer) for n in range(num_hidden_layer)]\n",
    "        self.output_layer = nn.Linear(dim_hidden_layer, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"CODE HERE: implement your forward propagation\n",
    "        \"\"\"\n",
    "        y = self.input_layer(x)\n",
    "        for activation, hidden_layer in zip(self.activation_layer, self.hidden_layers):\n",
    "            y = activation(y)\n",
    "            y = hidden_layer(y)\n",
    "        y = self.output_layer(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Experience Replay Buffer\n",
    "\n",
    "One main contribution of DQN is proposing to use the replay buffer. Here is the implementation of a simple replay buffer as a list of transitions (i.e., [(s, a, r, s', d), ....]). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    \"\"\" Implement the Replay Buffer as a class, which contains:\n",
    "            - self._data_buffer (list): a list variable to store all transition tuples.\n",
    "            - add: a function to add new transition tuple into the buffer\n",
    "            - sample_batch: a function to sample a batch training data from the Replay Buffer\n",
    "    \"\"\"\n",
    "    def __init__(self, buffer_size):\n",
    "        \"\"\"Args:\n",
    "               buffer_size (int): size of the replay buffer\n",
    "        \"\"\"\n",
    "        # total size of the replay buffer\n",
    "        self.total_size = buffer_size\n",
    "\n",
    "        # create a list to store the transitions\n",
    "        self._data_buffer = []\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data_buffer)\n",
    "\n",
    "    def add(self, obs, act, reward, next_obs, done):\n",
    "        # create a tuple\n",
    "        trans = (obs, act, reward, next_obs, done)\n",
    "\n",
    "        # interesting implementation\n",
    "        if self._next_idx >= len(self._data_buffer):\n",
    "            self._data_buffer.append(trans)\n",
    "        else:\n",
    "            self._data_buffer[self._next_idx] = trans\n",
    "\n",
    "        # increase the index\n",
    "        self._next_idx = (self._next_idx + 1) % self.total_size\n",
    "\n",
    "    def _encode_sample(self, indices):\n",
    "        \"\"\" Function to fetch the state, action, reward, next state, and done arrays.\n",
    "        \n",
    "            Args:\n",
    "                indices (list): list contains the index of all sampled transition tuples.\n",
    "        \"\"\"\n",
    "        # lists for transitions\n",
    "        obs_list, actions_list, rewards_list, next_obs_list, dones_list = [], [], [], [], []\n",
    "\n",
    "        # collect the data\n",
    "        for idx in indices:\n",
    "            # get the single transition\n",
    "            data = self._data_buffer[idx]\n",
    "            obs, act, reward, next_obs, d = data\n",
    "            # store to the list\n",
    "            obs_list.append(np.array(obs, copy=False))\n",
    "            actions_list.append(np.array(act, copy=False))\n",
    "            rewards_list.append(np.array(reward, copy=False))\n",
    "            next_obs_list.append(np.array(next_obs, copy=False))\n",
    "            dones_list.append(np.array(d, copy=False))\n",
    "        # return the sampled batch data as numpy arrays\n",
    "        return np.array(obs_list), np.array(actions_list), np.array(rewards_list), np.array(next_obs_list), np.array(\n",
    "            dones_list)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        \"\"\" Args:\n",
    "                batch_size (int): size of the sampled batch data.\n",
    "        \"\"\"\n",
    "        # sample indices with replaced\n",
    "        indices = [np.random.randint(0, len(self._data_buffer)) for _ in range(batch_size)]\n",
    "        return self._encode_sample(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a shedule for epsilon-greedy policy\n",
    "\n",
    "Here, we define a shedule function to return the epsilon for each time step t. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSchedule(object):\n",
    "    \"\"\" This schedule returns the value linearly\"\"\"\n",
    "    def __init__(self, start_value, end_value, duration):\n",
    "        # start value\n",
    "        self._start_value = start_value\n",
    "        # end value\n",
    "        self._end_value = end_value\n",
    "        # time steps that value changes from the start value to the end value\n",
    "        self._duration = duration\n",
    "        # difference between the start value and the end value\n",
    "        self._schedule_amount = end_value - start_value\n",
    "\n",
    "    def get_value(self, time):\n",
    "        # logic: if time > duration, use the end value, else use the scheduled value\n",
    "        \"\"\" CODE HERE: return the epsilon for each time step within the duration.\n",
    "        \"\"\"\n",
    "\n",
    "        sa = self._start_value + time / self._duration * self._schedule_amount\n",
    "        return self._end_value if time > self._duration else sa\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(object):\n",
    "    # initialize the agent\n",
    "    def __init__(self,\n",
    "                 params,\n",
    "                 ):\n",
    "        # save the parameters\n",
    "        self.params = params\n",
    "\n",
    "        # environment parameters\n",
    "        self.action_dim = params['action_dim']\n",
    "        self.obs_dim = params['observation_dim']\n",
    "\n",
    "        # executable actions\n",
    "        self.action_space = params['action_space']\n",
    "        self.width = params['width']\n",
    "        self.height = params['height']\n",
    "\n",
    "        # create value network\n",
    "        self.behavior_policy_net = DeepQNet(input_dim=params['observation_dim'],\n",
    "                                   num_hidden_layer=params['hidden_layer_num'],\n",
    "                                   dim_hidden_layer=params['hidden_layer_dim'],\n",
    "                                   output_dim=params['action_dim'])\n",
    "        # create target network\n",
    "        self.target_policy_net = DeepQNet(input_dim=params['observation_dim'],\n",
    "                                          num_hidden_layer=params['hidden_layer_num'],\n",
    "                                          dim_hidden_layer=params['hidden_layer_dim'],\n",
    "                                          output_dim=params['action_dim'])\n",
    "\n",
    "        # initialize target network with behavior network\n",
    "        self.behavior_policy_net.apply(customized_weights_init)\n",
    "        self.target_policy_net.load_state_dict(self.behavior_policy_net.state_dict())\n",
    "\n",
    "        # send the agent to a specific device: cpu or gpu\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.behavior_policy_net.to(self.device)\n",
    "        self.target_policy_net.to(self.device)\n",
    "\n",
    "        #loss function\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "        # optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.behavior_policy_net.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    # get action\n",
    "    def get_action(self, obs, eps):\n",
    "        if np.random.random() < eps:  # with probability eps, the agent selects a random action\n",
    "            state = obs\n",
    "            ind = 0\n",
    "            choices = []\n",
    "            for s in state:\n",
    "                if s == -1:\n",
    "                    choices.append(ind)\n",
    "                ind += 1\n",
    "            action = np.random.choice(choices)\n",
    "            return action\n",
    "        else:  # with probability 1 - eps, the agent selects a greedy policy\n",
    "            tensor_obs = self._arr_to_tensor(obs).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                q_values = self.behavior_policy_net(tensor_obs)\n",
    "                mask_step =  [ob == -1 for ob in obs]\n",
    "                mask = self._arr_to_tensor(mask_step).view(1, -1)\n",
    "                masked = torch.mul(q_values, mask)\n",
    "                action = masked.max(dim=1)[1].item()\n",
    "\n",
    "            return self.action_space[int(action)]\n",
    "    \n",
    "\n",
    "    # update behavior policy\n",
    "    def update_behavior_policy(self, batch_data):\n",
    "        # convert batch data to tensor and put them on device\n",
    "        batch_data_tensor = self._batch_to_tensor(batch_data)\n",
    "\n",
    "\n",
    "        # get the transition data\n",
    "        obs_tensor = batch_data_tensor['obs']\n",
    "        actions_tensor = batch_data_tensor['action']\n",
    "        next_obs_tensor = batch_data_tensor['next_obs']\n",
    "        rewards_tensor = batch_data_tensor['reward']\n",
    "        dones_tensor = batch_data_tensor['done']\n",
    "\n",
    "        o = self.behavior_policy_net(obs_tensor)\n",
    "\n",
    "        q_eval = o.gather(1, actions_tensor)\n",
    "        q_next = self.target_policy_net(next_obs_tensor).detach()\n",
    "        q_target = rewards_tensor + self.params[\"gamma\"] * q_next.max(1)[0].view(self.params[\"batch_size\"], 1) * (1 - dones_tensor)\n",
    "\n",
    "        #compute the loss\n",
    "        td_loss = self.loss_fn(q_eval, q_target)\n",
    "\n",
    "        # minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        td_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return td_loss.item()\n",
    "\n",
    "    # update update target policy\n",
    "    def update_target_policy(self):\n",
    "        # hard update\n",
    "        \"\"\"CODE HERE: \n",
    "                Copy the behavior policy network to the target network\n",
    "        \"\"\"\n",
    "        self.target_policy_net.load_state_dict(self.behavior_policy_net.state_dict())\n",
    "\n",
    "    # auxiliary functions\n",
    "    def _arr_to_tensor(self, arr):\n",
    "        arr = np.array(arr)\n",
    "        arr_tensor = torch.from_numpy(arr).float().to(self.device)\n",
    "        return arr_tensor\n",
    "\n",
    "    def _arr_to_bool_tensor(self, arr):\n",
    "        arr = np.array(arr)\n",
    "        arr_tensor = torch.from_numpy(arr).bool().to(self.device)\n",
    "        return arr_tensor\n",
    "\n",
    "    def _batch_to_tensor(self, batch_data):\n",
    "        # store the tensor\n",
    "        batch_data_tensor = {'obs': [], 'action': [], 'reward': [], 'next_obs': [], 'done': []}\n",
    "        # get the numpy arrays\n",
    "        obs_arr, action_arr, reward_arr, next_obs_arr, done_arr = batch_data\n",
    "        # convert to tensors\n",
    "        \n",
    "        batch_data_tensor['obs'] = torch.tensor(obs_arr, dtype=torch.float32).to(self.device)\n",
    "        batch_data_tensor['action'] = torch.tensor(action_arr).long().view(-1, 1).to(self.device)\n",
    "        batch_data_tensor['reward'] = torch.tensor(reward_arr, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "        batch_data_tensor['next_obs'] = torch.tensor(next_obs_arr, dtype=torch.float32).to(self.device)\n",
    "        batch_data_tensor['done'] = torch.tensor(done_arr, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "\n",
    "        return batch_data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn_agent(env, params):\n",
    "    # create the DQN agent\n",
    "    my_agent = DQNAgent(params)\n",
    "\n",
    "    # create the epsilon-greedy schedule\n",
    "    my_schedule = LinearSchedule(start_value=params['epsilon_start_value'],\n",
    "                                 end_value=params['epsilon_end_value'],\n",
    "                                 duration=params['epsilon_duration'])\n",
    "\n",
    "    # create the replay buffer\n",
    "    replay_buffer = ReplayBuffer(params['replay_buffer_size'])\n",
    "\n",
    "    # training variables\n",
    "    episode_t = 0\n",
    "    rewards = []\n",
    "    train_returns = []\n",
    "    train_loss = []\n",
    "    total_rounds = 0\n",
    "    wins = []\n",
    "\n",
    "    # reset the environment\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    # start training\n",
    "    pbar = tqdm.trange(params['total_training_time_step'])\n",
    "    last_best_return = 0\n",
    "    for t in pbar:\n",
    "        # scheduled epsilon at time step t\n",
    "        eps_t = my_schedule.get_value(t)\n",
    "        # get one epsilon-greedy action\n",
    "        action = my_agent.get_action(obs, eps_t)\n",
    "\n",
    "        # step in the environment\n",
    "        next_obs, reward, done, _, _ = env.step(action)\n",
    "\n",
    "        # add to the buffer\n",
    "        replay_buffer.add(obs, env.action_names.index(action), reward, next_obs, done)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        # check termination\n",
    "        if done:\n",
    "            # compute the return\n",
    "            if reward > 0:\n",
    "                wins.append(1)\n",
    "            else: \n",
    "                wins.append(0)\n",
    "            G = 0\n",
    "            for r in reversed(rewards):\n",
    "                G = r + params['gamma'] * G\n",
    "\n",
    "            if G > last_best_return:\n",
    "                torch.save(my_agent.behavior_policy_net.state_dict(), f\"./{params['model_name']}\")\n",
    "\n",
    "            # store the return\n",
    "            train_returns.append(G)\n",
    "            episode_idx = len(train_returns)\n",
    "\n",
    "            # print the information\n",
    "            pbar.set_description(\n",
    "                f\"Ep={episode_idx} | \"\n",
    "                f\"G={np.mean(train_returns[-10:]) if train_returns else 0:.2f} | \"\n",
    "                f\"Eps={eps_t}\"\n",
    "            )\n",
    "\n",
    "            # reset the environment\n",
    "            episode_t, rewards = 0, []\n",
    "            obs, _ = env.reset()\n",
    "        else:\n",
    "            # increment\n",
    "            obs = next_obs\n",
    "            episode_t += 1\n",
    "\n",
    "        if t > params['start_training_step']:\n",
    "            # update the behavior model\n",
    "            if not np.mod(t, params['freq_update_behavior_policy']):\n",
    "                \"\"\" CODE HERE:\n",
    "                    Update the behavior policy network\n",
    "                \"\"\"\n",
    "                loss = my_agent.update_behavior_policy(replay_buffer.sample_batch(params['batch_size']))\n",
    "                train_loss.append(loss)\n",
    "\n",
    "            # update the target model\n",
    "            if not np.mod(t, params['freq_update_target_policy']):\n",
    "                \"\"\" CODE HERE:\n",
    "                    Update the behavior policy network\n",
    "                \"\"\"\n",
    "                my_agent.update_target_policy()\n",
    "\n",
    "    # save the results\n",
    "    return train_returns, train_loss, wins, my_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(arr_list, legend_list, color_list, ylabel, fig_title):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        arr_list (list): list of results arrays to plot\n",
    "        legend_list (list): list of legends corresponding to each result array\n",
    "        color_list (list): list of color corresponding to each result array\n",
    "        ylabel (string): label of the Y axis\n",
    "\n",
    "        Note that, make sure the elements in the arr_list, legend_list and color_list are associated with each other correctly.\n",
    "        Do not forget to change the ylabel for different plots.\n",
    "    \"\"\"\n",
    "    # set the figure type\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # PLEASE NOTE: Change the labels for different plots\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(\"Time Steps\")\n",
    "\n",
    "    # ploth results\n",
    "    h_list = []\n",
    "    for arr, legend, color in zip(arr_list, legend_list, color_list):\n",
    "        # compute the standard error\n",
    "        arr_err = arr.std(axis=0) / np.sqrt(arr.shape[0])\n",
    "        # plot the mean\n",
    "        h, = ax.plot(range(arr.shape[1]), arr.mean(axis=0), color=color, label=legend)\n",
    "        # plot the confidence band\n",
    "        arr_err *= 1.96\n",
    "        ax.fill_between(range(arr.shape[1]), arr.mean(axis=0) - arr_err, arr.mean(axis=0) + arr_err, alpha=0.3,\n",
    "                        color=color)\n",
    "        # save the plot handle\n",
    "        h_list.append(h)\n",
    "\n",
    "    # plot legends\n",
    "    ax.set_title(f\"{fig_title}\")\n",
    "    ax.legend(handles=h_list)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep=112297 | G=15.01 | Eps=0.008: 100%|██████████| 1000000/1000000 [18:19<00:00, 909.33it/s]               \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #set the random seed\n",
    "    np.random.seed(123)\n",
    "    random.seed(123)\n",
    "    torch.manual_seed(123)\n",
    "\n",
    "    # create environment\n",
    "    width = 8\n",
    "    height = 8\n",
    "    mines = 5\n",
    "    my_env = MineSweeper(width, height, mines)\n",
    "\n",
    "    # create training parameters\n",
    "    train_parameters = {\n",
    "        'observation_dim': width * height,\n",
    "        'action_dim': width * height,\n",
    "        'action_space': my_env.action_names,\n",
    "        'hidden_layer_num': 2,\n",
    "        'hidden_layer_dim': 128,\n",
    "        'gamma': 0.99,\n",
    "\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "\n",
    "        'total_training_time_step': 1_000_000,\n",
    "\n",
    "        'epsilon_start_value': 1.0,\n",
    "        'epsilon_end_value': 0.008,\n",
    "        'epsilon_duration': 250000,\n",
    "\n",
    "        'replay_buffer_size': 100000,\n",
    "        'start_training_step': 2000,\n",
    "        'freq_update_behavior_policy': 4,\n",
    "        'freq_update_target_policy': 2000,\n",
    "\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-3,\n",
    "\n",
    "        'model_name': \"minesweeper.pt\"\n",
    "    }\n",
    "\n",
    "    # create experiment\n",
    "    train_returns, train_loss, wins, my_agent = train_dqn_agent(my_env, train_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    return [lst[i:i + n] for i in range(0, len(lst), n)]\n",
    "\n",
    "def averaged_returns(returns, chunk_size):\n",
    "    return [np.average(chunk) for chunk in chunks(returns, chunk_size)]\n",
    "\n",
    "averaged_2000_returns = averaged_returns(train_returns, 1000)\n",
    "  \n",
    "\n",
    "plot_curves([np.array([averaged_2000_returns])], ['dqn'], ['r'], 'discounted return', 'discounted returns wrt episode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curves([np.array([train_loss])], ['dqn'], ['r'], 'training loss', 'loss wrt training steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Play 1000 games, calculate win rate\n",
    "\n",
    "total = 100\n",
    "\n",
    "def calculate_win_rate(env, agent, total):\n",
    "  wins = 0\n",
    "  for n in range(total):\n",
    "    terminated = False    \n",
    "    state, _ = env.reset()\n",
    "    reward = 0 \n",
    "    while not terminated: \n",
    "      action = agent.get_action(state, 0)\n",
    "      \n",
    "      state, reward, terminated, _, _ =  env.step(action)\n",
    "\n",
    "    if n % 10 == 0:\n",
    "      print(\"round: \", n)\n",
    "    if reward == 8 * 8:\n",
    "      wins += 1\n",
    "  return wins/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  0\n",
      "round:  10\n",
      "round:  20\n",
      "round:  30\n",
      "round:  40\n",
      "round:  50\n",
      "round:  60\n",
      "round:  70\n",
      "round:  80\n",
      "round:  90\n",
      "Win Rate Sparse:  56.99999999999999\n"
     ]
    }
   ],
   "source": [
    "sparse_win = calculate_win_rate(my_env, my_agent, total)\n",
    "\n",
    "print(\"Win Rate Sparse: \", sparse_win * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7)\n",
      "[[-1 -1 -1 -1  1  0  0  0]\n",
      " [ 1  1  2  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1]\n",
      " [ 0  0  0  0  0  1  2 -1]\n",
      " [ 1  1  0  0  0  1 -1 -1]\n",
      " [-1  1  0  0  0  1  1  1]\n",
      " [-1  1  0  0  0  0  0  0]]\n",
      "(0, 7)\n",
      "[[-1 -1 -1 -1  1  0  0  0]\n",
      " [ 1  1  2  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1]\n",
      " [ 0  0  0  0  0  1  2 -1]\n",
      " [ 1  1  0  0  0  1 -1 -1]\n",
      " [-1  1  0  0  0  1  1  1]\n",
      " [ 1  1  0  0  0  0  0  0]]\n",
      "(2, 0)\n",
      "[[-1 -1  2 -1  1  0  0  0]\n",
      " [ 1  1  2  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1]\n",
      " [ 0  0  0  0  0  1  2 -1]\n",
      " [ 1  1  0  0  0  1 -1 -1]\n",
      " [-1  1  0  0  0  1  1  1]\n",
      " [ 1  1  0  0  0  0  0  0]]\n",
      "(7, 5)\n",
      "[[-1 -1  2 -1  1  0  0  0]\n",
      " [ 1  1  2  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1]\n",
      " [ 0  0  0  0  0  1  2 -1]\n",
      " [ 1  1  0  0  0  1 -1  2]\n",
      " [-1  1  0  0  0  1  1  1]\n",
      " [ 1  1  0  0  0  0  0  0]]\n",
      "(0, 0)\n",
      "[[ 1 -1  2 -1  1  0  0  0]\n",
      " [ 1  1  2  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1]\n",
      " [ 0  0  0  0  0  1  2 -1]\n",
      " [ 1  1  0  0  0  1 -1  2]\n",
      " [-1  1  0  0  0  1  1  1]\n",
      " [ 1  1  0  0  0  0  0  0]]\n",
      "round:  0\n",
      "win\n"
     ]
    }
   ],
   "source": [
    "def action_index_to_coord(index):\n",
    "    y = math.floor(index / 8) \n",
    "    x = index - y * 8\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "for n in range(1):\n",
    "  terminated = False    \n",
    "  state, _ = my_env.reset()\n",
    "  reward = 0 \n",
    "  while not terminated: \n",
    "    action = my_agent.get_action(state, 0)\n",
    "    print(action_index_to_coord(action))\n",
    "    \n",
    "    state, reward, terminated, _, _ =  my_env.step(action)\n",
    "    print(my_env.state)\n",
    "\n",
    "  if n % 10 == 0:\n",
    "    print(\"round: \", n)\n",
    "  if reward == 8 * 8:\n",
    "    print(\"win\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dueling DQN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DuelingDqn(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DuelingDqn, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_value = nn.Linear(256, 512)\n",
    "        self.fc_adv = nn.Linear(256, 512)\n",
    "\n",
    "        self.value = nn.Linear(512, 1)\n",
    "        self.adv = nn.Linear(512, output_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        y = self.relu(self.fc1(state))\n",
    "        value = self.relu(self.fc_value(y))\n",
    "        adv = self.relu(self.fc_adv(y))\n",
    "\n",
    "        value = self.value(value)\n",
    "        adv = self.adv(adv)\n",
    "\n",
    "        advAverage = torch.mean(adv, dim=1, keepdim=True)\n",
    "        Q = value + adv - advAverage\n",
    "\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingDQNAgent(object):\n",
    "    # initialize the agent\n",
    "    def __init__(self,\n",
    "                 params,\n",
    "                 ):\n",
    "        # save the parameters\n",
    "        self.params = params\n",
    "\n",
    "        # environment parameters\n",
    "        self.action_dim = params['action_dim']\n",
    "        self.obs_dim = params['observation_dim']\n",
    "\n",
    "        # executable actions\n",
    "        self.action_space = params['action_space']\n",
    "        self.width = params['width']\n",
    "        self.height = params['height']\n",
    "\n",
    "        # create value network\n",
    "        self.behavior_policy_net = DuelingDqn(input_dim=params['observation_dim'],\n",
    "                                   output_dim=params['action_dim'])\n",
    "        # create target network\n",
    "        self.target_policy_net = DuelingDqn(input_dim=params['observation_dim'],\n",
    "                                          output_dim=params['action_dim'])\n",
    "\n",
    "        # initialize target network with behavior network\n",
    "        self.behavior_policy_net.apply(customized_weights_init)\n",
    "        self.target_policy_net.load_state_dict(self.behavior_policy_net.state_dict())\n",
    "\n",
    "        # send the agent to a specific device: cpu or gpu\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.behavior_policy_net.to(self.device)\n",
    "        self.target_policy_net.to(self.device)\n",
    "\n",
    "        #loss function\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "        # optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.behavior_policy_net.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    # get action\n",
    "    def get_action(self, obs, eps):\n",
    "        if np.random.random() < eps:  # with probability eps, the agent selects a random action\n",
    "            state = obs\n",
    "            ind = 0\n",
    "            choices = []\n",
    "            for s in state:\n",
    "                if s == -1:\n",
    "                    choices.append(ind)\n",
    "                ind += 1\n",
    "            action = np.random.choice(choices)\n",
    "            return action\n",
    "        else:  # with probability 1 - eps, the agent selects a greedy policy\n",
    "            tensor_obs = self._arr_to_tensor(obs).view(1, -1)\n",
    "            with torch.no_grad():\n",
    "                q_values = self.behavior_policy_net(tensor_obs)\n",
    "                mask_step =  [ob == -1 for ob in obs]\n",
    "                mask = self._arr_to_tensor(mask_step).view(1, -1)\n",
    "                masked = torch.mul(q_values, mask)\n",
    "                action = masked.max(dim=1)[1].item()\n",
    "\n",
    "            return self.action_space[int(action)]\n",
    "    \n",
    "\n",
    "    # update behavior policy\n",
    "    def update_behavior_policy(self, batch_data):\n",
    "        # convert batch data to tensor and put them on device\n",
    "        batch_data_tensor = self._batch_to_tensor(batch_data)\n",
    "\n",
    "\n",
    "        # get the transition data\n",
    "        obs_tensor = batch_data_tensor['obs']\n",
    "        actions_tensor = batch_data_tensor['action']\n",
    "        next_obs_tensor = batch_data_tensor['next_obs']\n",
    "        rewards_tensor = batch_data_tensor['reward']\n",
    "        dones_tensor = batch_data_tensor['done']\n",
    "\n",
    "        o = self.behavior_policy_net(obs_tensor)\n",
    "        q_eval = o.gather(1, actions_tensor)\n",
    "        q_next = self.target_policy_net(next_obs_tensor).detach()\n",
    "        q_target = rewards_tensor + self.params[\"gamma\"] * q_next.max(1)[0].view(self.params[\"batch_size\"], 1) * (1 - dones_tensor)\n",
    "\n",
    "        #compute the loss\n",
    "        td_loss = self.loss_fn(q_eval, q_target)\n",
    "\n",
    "        # minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        td_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return td_loss.item()\n",
    "\n",
    "    # update update target policy\n",
    "    def update_target_policy(self):\n",
    "        # hard update\n",
    "        \"\"\"CODE HERE: \n",
    "                Copy the behavior policy network to the target network\n",
    "        \"\"\"\n",
    "        self.target_policy_net.load_state_dict(self.behavior_policy_net.state_dict())\n",
    "\n",
    "    # auxiliary functions\n",
    "    def _arr_to_tensor(self, arr):\n",
    "        arr = np.array(arr)\n",
    "        arr_tensor = torch.from_numpy(arr).float().to(self.device)\n",
    "        return arr_tensor\n",
    "\n",
    "    def _batch_to_tensor(self, batch_data):\n",
    "        # store the tensor\n",
    "        batch_data_tensor = {'obs': [], 'action': [], 'reward': [], 'next_obs': [], 'done': []}\n",
    "        # get the numpy arrays\n",
    "        obs_arr, action_arr, reward_arr, next_obs_arr, done_arr = batch_data\n",
    "        # convert to tensors\n",
    "        \n",
    "        batch_data_tensor['obs'] = torch.tensor(obs_arr, dtype=torch.float32).to(self.device)\n",
    "        batch_data_tensor['action'] = torch.tensor(action_arr).long().view(-1, 1).to(self.device)\n",
    "        batch_data_tensor['reward'] = torch.tensor(reward_arr, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "        batch_data_tensor['next_obs'] = torch.tensor(next_obs_arr, dtype=torch.float32).to(self.device)\n",
    "        batch_data_tensor['done'] = torch.tensor(done_arr, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "\n",
    "        return batch_data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dueling_dqn_agent(env, params):\n",
    "    # create the DQN agent\n",
    "    my_agent = DuelingDQNAgent(params)\n",
    "\n",
    "    # create the epsilon-greedy schedule\n",
    "    my_schedule = LinearSchedule(start_value=params['epsilon_start_value'],\n",
    "                                 end_value=params['epsilon_end_value'],\n",
    "                                 duration=params['epsilon_duration'])\n",
    "\n",
    "    # create the replay buffer\n",
    "    replay_buffer = ReplayBuffer(params['replay_buffer_size'])\n",
    "\n",
    "    # training variables\n",
    "    episode_t = 0\n",
    "    rewards = []\n",
    "    train_returns = []\n",
    "    train_loss = []\n",
    "    total_rounds = 0\n",
    "    wins = []\n",
    "\n",
    "    # reset the environment\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    # start training\n",
    "    pbar = tqdm.trange(params['total_training_time_step'])\n",
    "    last_best_return = 0\n",
    "    for t in pbar:\n",
    "        # scheduled epsilon at time step t\n",
    "        eps_t = my_schedule.get_value(t)\n",
    "        # get one epsilon-greedy action\n",
    "        action = my_agent.get_action(obs, eps_t)\n",
    "\n",
    "        # step in the environment\n",
    "        next_obs, reward, done, _, _ = env.step(action)\n",
    "\n",
    "        # add to the buffer\n",
    "        replay_buffer.add(obs, env.action_names.index(action), reward, next_obs, done)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        # check termination\n",
    "        if done:\n",
    "            # compute the return\n",
    "            if reward > 0:\n",
    "                wins.append(1)\n",
    "            else: \n",
    "                wins.append(0)\n",
    "            G = 0\n",
    "            for r in reversed(rewards):\n",
    "                G = r + params['gamma'] * G\n",
    "\n",
    "            if G > last_best_return:\n",
    "                torch.save(my_agent.behavior_policy_net.state_dict(), f\"./{params['model_name']}\")\n",
    "\n",
    "            # store the return\n",
    "            train_returns.append(G)\n",
    "            episode_idx = len(train_returns)\n",
    "\n",
    "            # print the information\n",
    "            pbar.set_description(\n",
    "                f\"Ep={episode_idx} | \"\n",
    "                f\"G={np.mean(train_returns[-10:]) if train_returns else 0:.2f} | \"\n",
    "                f\"Eps={eps_t}\"\n",
    "            )\n",
    "\n",
    "            # reset the environment\n",
    "            episode_t, rewards = 0, []\n",
    "            obs, _ = env.reset()\n",
    "        else:\n",
    "            # increment\n",
    "            obs = next_obs\n",
    "            episode_t += 1\n",
    "\n",
    "        if t > params['start_training_step']:\n",
    "            # update the behavior model\n",
    "            if not np.mod(t, params['freq_update_behavior_policy']):\n",
    "                \"\"\" CODE HERE:\n",
    "                    Update the behavior policy network\n",
    "                \"\"\"\n",
    "                loss = my_agent.update_behavior_policy(replay_buffer.sample_batch(params['batch_size']))\n",
    "                train_loss.append(loss)\n",
    "\n",
    "            # update the target model\n",
    "            if not np.mod(t, params['freq_update_target_policy']):\n",
    "                \"\"\" CODE HERE:\n",
    "                    Update the behavior policy network\n",
    "                \"\"\"\n",
    "                my_agent.update_target_policy()\n",
    "\n",
    "    # save the results\n",
    "    return train_returns, train_loss, wins, my_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep=126222 | G=-56.75 | Eps=0.008: 100%|██████████| 1000000/1000000 [33:10<00:00, 502.48it/s]             \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # set the random seed\n",
    "    np.random.seed(123)\n",
    "    random.seed(123)\n",
    "    torch.manual_seed(123)\n",
    "\n",
    "    # create environment\n",
    "    width = 8\n",
    "    height = 8\n",
    "    mines = 5\n",
    "    sparse_env = MineSweeper(width, height, mines)\n",
    "\n",
    "    # create training parameters\n",
    "    train_parameters = {\n",
    "        'observation_dim': width * height,\n",
    "        'action_dim': width * height,\n",
    "        'action_space': my_env.action_names,\n",
    "        'hidden_layer_num': 2,\n",
    "        'hidden_layer_dim': 128,\n",
    "        'gamma': 0.99,\n",
    "\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "\n",
    "        'total_training_time_step': 1_000_000,\n",
    "\n",
    "        'epsilon_start_value': 1.0,\n",
    "        'epsilon_end_value': 0.01,\n",
    "        'epsilon_duration': 250000,\n",
    "\n",
    "        'replay_buffer_size': 100000,\n",
    "        'start_training_step': 2000,\n",
    "        'freq_update_behavior_policy': 4,\n",
    "        'freq_update_target_policy': 2000,\n",
    "\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-3,\n",
    "\n",
    "        'model_name': \"minesweeper.pt\"\n",
    "    }\n",
    "\n",
    "    # create experiment\n",
    "    train_returns, train_loss, wins, dueling_agent = train_dueling_dqn_agent(sparse_env, train_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  0\n",
      "round:  10\n",
      "round:  20\n",
      "round:  30\n",
      "round:  40\n",
      "round:  50\n",
      "round:  60\n",
      "round:  70\n",
      "round:  80\n",
      "round:  90\n",
      "round:  100\n",
      "round:  110\n",
      "round:  120\n",
      "round:  130\n",
      "round:  140\n",
      "round:  150\n",
      "round:  160\n",
      "round:  170\n",
      "round:  180\n",
      "round:  190\n",
      "round:  200\n",
      "round:  210\n",
      "round:  220\n",
      "round:  230\n",
      "round:  240\n",
      "round:  250\n",
      "round:  260\n",
      "round:  270\n",
      "round:  280\n",
      "round:  290\n",
      "round:  300\n",
      "round:  310\n",
      "round:  320\n",
      "round:  330\n",
      "round:  340\n",
      "round:  350\n",
      "round:  360\n",
      "round:  370\n",
      "round:  380\n",
      "round:  390\n",
      "round:  400\n",
      "round:  410\n",
      "round:  420\n",
      "round:  430\n",
      "round:  440\n",
      "round:  450\n",
      "round:  460\n",
      "round:  470\n",
      "round:  480\n",
      "round:  490\n",
      "round:  500\n",
      "round:  510\n",
      "round:  520\n",
      "round:  530\n",
      "round:  540\n",
      "round:  550\n",
      "round:  560\n",
      "round:  570\n",
      "round:  580\n",
      "round:  590\n",
      "round:  600\n",
      "round:  610\n",
      "round:  620\n",
      "round:  630\n",
      "round:  640\n",
      "round:  650\n",
      "round:  660\n",
      "round:  670\n",
      "round:  680\n",
      "round:  690\n",
      "round:  700\n",
      "round:  710\n",
      "round:  720\n",
      "round:  730\n",
      "round:  740\n",
      "round:  750\n",
      "round:  760\n",
      "round:  770\n",
      "round:  780\n",
      "round:  790\n",
      "round:  800\n",
      "round:  810\n",
      "round:  820\n",
      "round:  830\n",
      "round:  840\n",
      "round:  850\n",
      "round:  860\n",
      "round:  870\n",
      "round:  880\n",
      "round:  890\n",
      "round:  900\n",
      "round:  910\n",
      "round:  920\n",
      "round:  930\n",
      "round:  940\n",
      "round:  950\n",
      "round:  960\n",
      "round:  970\n",
      "round:  980\n",
      "round:  990\n",
      "Win Rate Sparse:  5.7\n"
     ]
    }
   ],
   "source": [
    "sparse_win = calculate_win_rate(sparse_env, dueling_agent, 1000)\n",
    "\n",
    "\n",
    "print(\"Win Rate Sparse: \", sparse_win * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
